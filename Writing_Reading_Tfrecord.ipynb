{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "### Import the necessary libraries ###\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import face_recognition as fr\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n"
     ]
    }
   ],
   "source": [
    "### Load in the dataset that we want the test both models on ###\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "DATA_DIR = './data'\n",
    "WIDTH, HEIGHT, CHANNELS = 170, 170, 3\n",
    "\n",
    "faces, labels = [], []\n",
    "\n",
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "''' ==================================================================================================== '''\n",
    "\n",
    "def detect_face(img):\n",
    "    ### take an image and return face location(s) ###\n",
    "    location = face_recognition.face_locations(img)\n",
    "    \n",
    "    if(len(location) == 0):\n",
    "        return None\n",
    "    \n",
    "    top, right, bottom, left = location[0]\n",
    "    return (left, top, right, bottom)\n",
    "\n",
    "def preprocessing(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (170, 170))\n",
    "\n",
    "    ### Standardize the image ###\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    image = (image - mean)/std\n",
    "\n",
    "    return image\n",
    "\n",
    "count = 0\n",
    "source_id = 0\n",
    "record_file = 'images.tfrecord'\n",
    "width, height, channels = 128,128,3\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for (dir_, dirs, files) in os.walk(DATA_DIR):\n",
    "        file_count = 0\n",
    "        for file_ in files:\n",
    "            file_count += 1\n",
    "            count += 1\n",
    "\n",
    "            if(file_count >= 30):\n",
    "                continue\n",
    "\n",
    "            abs_path = os.path.join(dir_, file_)\n",
    "\n",
    "            # print('File %s processed ' % abs_path)\n",
    "            feature = {\n",
    "                'image/filename' : _bytes_feature(abs_path.encode()),\n",
    "                'image/encoded' : _bytes_feature(open(abs_path, 'rb').read()),\n",
    "                'image/source_id' : _int64_feature(source_id)\n",
    "            }\n",
    "\n",
    "            tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "    source_id += 1\n",
    "\n",
    "print(count)\n",
    "faces = np.array(faces)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting train and test datasets .. \n",
      "Getting dataset length\n",
      "17.875\n",
      "15\n",
      "2\n",
      "Splitting train - val\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/source_id': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    # Parse the input tf.train.Example proto using the dictionary above.\n",
    "    x = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    x_train = tf.image.decode_jpeg(x['image/encoded'], channels=3)\n",
    "    x_train = tf.image.resize(x_train, (width, height))\n",
    "    y_train = tf.one_hot(x['image/source_id'], 5000)\n",
    "        \n",
    "    return (x_train, y_train), y_train\n",
    "\n",
    "### Parse the tfrecord to a training dataset ###\n",
    "def load_tfrecord_dataset(tfrecord_name, batch_size, shuffle=True, buffer_size=400000):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    print('Getting dataset length')\n",
    "    dataset_len = 572 #int(sum(1 for _ in tf.data.TFRecordDataset(tfrecord_name)))\n",
    "    print(dataset_len / batch_size)\n",
    "    train_size = int(0.85 * (dataset_len / batch_size))\n",
    "    print(train_size)\n",
    "    val_size = int(0.15 * (dataset_len / batch_size))\n",
    "    print(val_size)\n",
    "\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    dataset = raw_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    print('Splitting train - val')\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    val_dataset = val_dataset.repeat()\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "print('Getting train and test datasets .. ')\n",
    "train_dataset, test_dataset = load_tfrecord_dataset('images.tfrecord', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "iterator = train_dataset.make_initializable_iterator()\n",
    "batch = iterator.get_next()\n",
    "\n",
    "(trainX, trainY), trainY = batch\n",
    "trainX.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
